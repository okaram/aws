= S3 - Simple Storage Service
:toc: left
:sourcedir: /Users/curri/projects/aws/python/s3
:source-highlighter: pygments

AWS S3 allows us to store and retrieve files in the cloud; we have cheap and virtually unlimited storage.

S3 stores files in *buckets*, which have a globally-unique name (that means you need a bucket name that is different than everybody else in AWS, even if they have a different account).

As with most resources, we can create a bucket using cloudformation, the aws cli, or the console. I will use cloudformation when possible.

== creating the bucket

The simplest cloudformation template would just define one resource, of type `AWS::S3::Bucket`. The only required property is `BucketName`, which is a globally unique name (S3 is one of the oldest AWS services, and they went with global names, rather than per-account). 

So, a simple CF template would look like: (remember the bucket name has to be unique, so replace it with a name of your own if you run this). 

[source,YAML]
.Simplest yml bucket
----
include::{sourcedir}/SimplestBucket.yml[]
----

== Downloading a file

AWS provides a REST API for most of its services. https://boto3.readthedocs.io/en/latest/[`boto3`] is the standard python (well, python 3) library for accessing aws services ; the library allows you to get a 'low' level (still, quite high level compared with Java :)  client, which maps almost one-to-one with api calls, and a higher-level resource interface. 

I will be using the low-level clients, since they are more transferable to other languages. Documentation for the s3 client is at http://boto3.readthedocs.io/en/latest/reference/services/s3.html#client[`http://boto3.readthedocs.io/en/latest/reference/services/s3.html#client`].


boto3 (and python) are amazing, so a program to download a file 
is only a few lines:
(we take the bucket and file as program arguments)
[source,Groovy]
.download.groovy
----
include::{sourcedir}/download.groovy[]
----

== Uploading a file

Uploading through S3Client directly involves uploading a file in several parts, and then assembling the parts, which makes it much more convenient to use a http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/transfer/TransferManager.html[`TransferManager`], which takes care of breaking the file in parts and uploading all the parts (you can also use it to download files). A simple file uploader would look as follows:
[source,groovy]
.download.groovy
----
include::{sourcedir}/upload.groovy[]
----

== Listing all files in a bucket

S3 does not really have folders, (but we can use any separator (usually /) within  file names to simulate folders).

A program to list the files in a bucket, without regard of any folders (would include ALL files, regardles of which folder it belongs to) is shown below. It also illustrates a common pattern within the AWS API and SDK; if an operation can return a list of infinite (well, unbound) size, then the API will return just a portion of the list, and then a continuation token; if we get a continuation token, then we know that we need to call again, passing that token, to get more elements from the list.

Here we use a http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/model/ListObjectsV2Request.html[ListObjectsV2Request]
[source,Groovy]
.ls.groovy
----
include::{sourcedir}/ls.groovy[]
----

== Bucket with web configuration and authorization for everybody to read
[source,YAML]
.Bucket with web configuration and a policy allowing anybody to read 
----
include::{sourcedir}/FirstBucket.yml[]
----

== TODO

* ls with folders, withDelimiter/withPrefix , getCommonPrefixes
* Permission policies with CF
* Deletion policies etc
* Temporary access URLs
